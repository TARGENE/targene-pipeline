<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Some Runtime considerations · TarGene</title><meta name="title" content="Some Runtime considerations · TarGene"/><meta property="og:title" content="Some Runtime considerations · TarGene"/><meta property="twitter:title" content="Some Runtime considerations · TarGene"/><meta name="description" content="Documentation for TarGene."/><meta property="og:description" content="Documentation for TarGene."/><meta property="twitter:description" content="Documentation for TarGene."/><meta property="og:url" content="https://TARGENE.github.io/targene-pipeline/runtime_considerations/"/><meta property="twitter:url" content="https://TARGENE.github.io/targene-pipeline/runtime_considerations/"/><link rel="canonical" href="https://TARGENE.github.io/targene-pipeline/runtime_considerations/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">TarGene</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/setup/">Setup (Read First)</a></li><li><a class="tocitem" href="../examples/gwas/">GWAS</a></li><li><a class="tocitem" href="../examples/phewas/">PheWAS</a></li><li><a class="tocitem" href="../examples/interactions/">Interaction Study</a></li><li><a class="tocitem" href="../examples/allofus/">All of Us</a></li></ul></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../overview/">Nextflow Basics</a></li><li><a class="tocitem" href="../all_workflows_parameters/">Index of Workflows Parameters</a></li><li class="is-active"><a class="tocitem" href>Some Runtime considerations</a><ul class="internal"><li><a class="tocitem" href="#The-Drivers-of-Complexity"><span>The Drivers of Complexity</span></a></li><li><a class="tocitem" href="#Controlling-Runtime-via-Parallelisation"><span>Controlling Runtime via Parallelisation</span></a></li><li><a class="tocitem" href="#Examples-Through-Study-Designs"><span>Examples Through Study Designs</span></a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">The Discovery Workflow</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../targene/overview/">Overview</a></li><li><a class="tocitem" href="../targene/data_sources/">Genetic and Traits Data</a></li><li><a class="tocitem" href="../targene/confounding_adjustment/">PCA Adjustment</a></li><li><a class="tocitem" href="../targene/study_designs/">Defining the Estimands of Interest</a></li><li><a class="tocitem" href="../targene/tmle/">Specifying a Targeted Estimator</a></li><li><a class="tocitem" href="../targene/sieve_variance/">Correcting for population relatedness (Experimental)</a></li><li><a class="tocitem" href="../targene/miscellaneous/">Final Tweaks</a></li><li><a class="tocitem" href="../targene/outputs/">Understanding TarGene&#39;s Outputs</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-5" type="checkbox"/><label class="tocitem" for="menuitem-3-5"><span class="docs-label">The Simulation Workflows (Experimental)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../simulations/overview/">Overview</a></li><li><a class="tocitem" href="../simulations/null_simulation/">Null Simulation</a></li><li><a class="tocitem" href="../simulations/realistic_simulation/">Realistic Simulation</a></li><li><a class="tocitem" href="../simulations/simulation_outputs/">Description of Simulations Outputs</a></li></ul></li></ul></li><li><span class="tocitem">Secondary Workflows</span><ul><li><a class="tocitem" href="../secondary_workflows/pca/">The PCA Workflow</a></li><li><a class="tocitem" href="../secondary_workflows/make_dataset/">The Make Dataset Workflow</a></li></ul></li><li><span class="tocitem">Developper Guide</span><ul><li><a class="tocitem" href="../developer_guide/project_organization/">Project Organization</a></li><li><a class="tocitem" href="../developer_guide/contribution_guide/">Contributing</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>Some Runtime considerations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Some Runtime considerations</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TARGENE/targene-pipeline/blob/main/docs/src/runtime_considerations.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Some-Runtime-considerations"><a class="docs-heading-anchor" href="#Some-Runtime-considerations">Some Runtime considerations</a><a id="Some-Runtime-considerations-1"></a><a class="docs-heading-anchor-permalink" href="#Some-Runtime-considerations" title="Permalink"></a></h1><p>Targeted Learning can quickly become computationally intensive compared to traditional parametric inference. Here, we describe the drivers of complexity, explain the tricks we use to keep it under control and illustrate with two typical study designs.</p><h2 id="The-Drivers-of-Complexity"><a class="docs-heading-anchor" href="#The-Drivers-of-Complexity">The Drivers of Complexity</a><a id="The-Drivers-of-Complexity-1"></a><a class="docs-heading-anchor-permalink" href="#The-Drivers-of-Complexity" title="Permalink"></a></h2><p>Remember that for each estimand of interest, a Targeted Learning estimator requires 3 ingredients:</p><ul><li>An estimator for the propensity score: <span>$G = P(T|W)$</span>.</li><li>An estimator for the outcome&#39;s mean: <span>$Q_Y = \mathbb{E}[Y|T, W]$</span>.</li><li>A targeting (or debiasing) step.</li></ul><h3 id="Complexity-Driven-by-the-Targeting-Step"><a class="docs-heading-anchor" href="#Complexity-Driven-by-the-Targeting-Step">Complexity Driven by the Targeting Step</a><a id="Complexity-Driven-by-the-Targeting-Step-1"></a><a class="docs-heading-anchor-permalink" href="#Complexity-Driven-by-the-Targeting-Step" title="Permalink"></a></h3><p>The targeting step is the essential ingredient that makes the estimators in TarGene &quot;work&quot;. However, all semi-parametric estimators work slightly differently and are thus not computationally equal. For instance the targeting step of the Targeted Minimum-Loss Estimator (TMLE) requires a generalised linear model fit while the One-Step Estimator (OSE) only requires a simple computation of the bias. The benefit is that, unlike the OSE, the TMLE is guaranteed to always respect the natural bounds of the genetic effect (think probabilities between 0 and 1).</p><h3 id="Complexity-Driven-by-ML-Models"><a class="docs-heading-anchor" href="#Complexity-Driven-by-ML-Models">Complexity Driven by ML Models</a><a id="Complexity-Driven-by-ML-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Complexity-Driven-by-ML-Models" title="Permalink"></a></h3><p>The more complex the machine-learning models, the longer the runtime. For instance using a generalized linear model for both <span>$G$</span> and <span>$Q_Y$</span> would only roughly double the runtime of a regular estimation strategy based on linear models. In contrast, a Super Learning strategy relies on cross-validation and multiple models fits, and is thus much more expensive. However, because the <span>$G$</span> model does not involve the outcome <span>$Y$</span>, it can be efficiently reused hence reducing computational burden if many outcomes are of interest. This is particularly interesting in the PheWAS setting where a single <span>$G$</span> model can be used throughout for all estimands.</p><p>Similarly, but to a smaller extent, the above targeting step is specific to the variant&#39;s genotype change under investigation (e.g., <span>$CC \rightarrow CT$</span>). Most of the time, multiple genotype changes are of interest (e.g., <span>$CC \rightarrow CT$</span> and <span>$CT \rightarrow TT$</span>) and both <span>$Q_Y$</span> and <span>$G$</span> can be reused across these changes.</p><h3 id="Complexity-Driven-by-the-Estimators"><a class="docs-heading-anchor" href="#Complexity-Driven-by-the-Estimators">Complexity Driven by the Estimators</a><a id="Complexity-Driven-by-the-Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Complexity-Driven-by-the-Estimators" title="Permalink"></a></h3><p>All estimators exist in both a canonical and cross-validated version. The latter relaxes some non-parametric conditions under which the estimators will be asymptotically unbiased. However, it comes at a cost since it requires splitting the data into K folds and fitting the <span>$G$</span> and <span>$Q_Y$</span> models K times instead of once. Furthermore, the <span>$G$</span> model cannot be reused anymore because this outer cross-validation scheme is typically stratified by the outcome as well.</p><h2 id="Controlling-Runtime-via-Parallelisation"><a class="docs-heading-anchor" href="#Controlling-Runtime-via-Parallelisation">Controlling Runtime via Parallelisation</a><a id="Controlling-Runtime-via-Parallelisation-1"></a><a class="docs-heading-anchor-permalink" href="#Controlling-Runtime-via-Parallelisation" title="Permalink"></a></h2><p>If you are running TarGene on a high performance computing platform, you have access to many nodes that can be leveraged. For that purpose we use batching, that is we split all the run&#39;s estimands in &quot;cleverly&quot; organised batches to maximize caching of machine learning models. This is controlled by the <code>BATCH_SIZE (default: 50)</code> parameter which can be adjusted based on your specific study and platform.</p><div class="admonition is-success"><header class="admonition-header">Estimation Resources</header><div class="admonition-body"><p>The estimation is likely going to be the rate limiting step of your run. Each estimation process can further be adjusted in your config file based on your specific problem. For example as follows to retry with more memory as follows. </p><pre><code class="language-config hljs">process{
    withName: TMLE {
        memory = { 10.GB * task.attempt  }
        time = { 48.hour }
        cpus = 1
    }
}</code></pre></div></div><h2 id="Examples-Through-Study-Designs"><a class="docs-heading-anchor" href="#Examples-Through-Study-Designs">Examples Through Study Designs</a><a id="Examples-Through-Study-Designs-1"></a><a class="docs-heading-anchor-permalink" href="#Examples-Through-Study-Designs" title="Permalink"></a></h2><p>The numbers provided below were obtained with TarGene v0.9.0 and better performance is expected in the future.</p><h3 id="The-PheWAS-study-design"><a class="docs-heading-anchor" href="#The-PheWAS-study-design">The PheWAS study design</a><a id="The-PheWAS-study-design-1"></a><a class="docs-heading-anchor-permalink" href="#The-PheWAS-study-design" title="Permalink"></a></h3><p>In a PheWAS, one is interested in the effect of a genetic variation across many outcomes (typically around 1000). Because the treatment variable is always the same, the propensity score <span>$G$</span> can be reused across all parameters, which drastically reduces computational complexity.</p><p>With this setup in mind, the computational complexity is mostly driven by the specification of the learning algorithms for <span>$Q_Y$</span>, which will have to be fitted for each outcome. In the table below are presented some runtimes for various specifications of <span>$G$</span> and <span>$Q_Y$</span> using a single cpu. The &quot;Unit runtime&quot; is the average runtime across all estimands averaged over 10 traits and can roughly be extrapolated to bigger studies.</p><table><tr><th style="text-align: right">Estimator</th><th style="text-align: center">Unit runtime (s)</th><th style="text-align: center">Extrapolated runtime to 1000 outcomes</th></tr><tr><td style="text-align: right"><code>glm</code></td><td style="text-align: center">4.65</td><td style="text-align: center">≈ 1h20</td></tr><tr><td style="text-align: right"><code>glmnet</code></td><td style="text-align: center">7.19</td><td style="text-align: center">≈ 2h</td></tr><tr><td style="text-align: right"><code>G-superlearning-Q-glmnet</code></td><td style="text-align: center">50.05</td><td style="text-align: center">≈ 13h45</td></tr><tr><td style="text-align: right"><code>superlearning</code></td><td style="text-align: center">168.98</td><td style="text-align: center">≈ 46h</td></tr></table><p>Depending on the available resources, this means one can probably afford to use more expensive ML models. This is because the above does not leverage any sort of parallelisation.</p><h3 id="The-GWAS-study-design"><a class="docs-heading-anchor" href="#The-GWAS-study-design">The GWAS study design</a><a id="The-GWAS-study-design-1"></a><a class="docs-heading-anchor-permalink" href="#The-GWAS-study-design" title="Permalink"></a></h3><p>In a GWAS, the outcome variable is held fixed and we are interested in the effects of very many genetic variations on this outcome (typically 800 000 for a genotyping array). The propensity score cannot be reused across parameters resulting in a more expensive run.</p><p>In this case we look at 3 different genetic variations and only one outcome. In the table below are presented some runtimes for various specifications of <span>$G$</span> and <span>$Q_Y$</span> using a single cpu. The &quot;Unit runtime&quot; is the average runtime across all estimands and can roughly be extrapolated to bigger studies.</p><table><tr><th style="text-align: right">Estimator file</th><th style="text-align: center">Continuous outcome unit runtime (s)</th><th style="text-align: center">Binary outcome unit runtime (s)</th><th style="text-align: center">Projected Time on HPC (200 folds //)</th></tr><tr><td style="text-align: right"><code>glm</code></td><td style="text-align: center">5.64</td><td style="text-align: center">6.14</td><td style="text-align: center">≈ 6h30</td></tr><tr><td style="text-align: right"><code>glmnet</code></td><td style="text-align: center">17.46</td><td style="text-align: center">22.24</td><td style="text-align: center">≈ 22h</td></tr><tr><td style="text-align: right"><code>G-superlearning-Q-glmnet</code></td><td style="text-align: center">430.54</td><td style="text-align: center">438.67</td><td style="text-align: center">≈ 20 days</td></tr><tr><td style="text-align: right"><code>superlearning</code></td><td style="text-align: center">511.26</td><td style="text-align: center">567.72</td><td style="text-align: center">≈ 24 days</td></tr></table><p>We can see that modern high performance computing platforms definitely enable this study design when using GLMs or GLMNets. It is unlikely however, that you will be able to use Super Learning for any of <span>$G$</span> or <span>$Q_Y$</span> if you don&#39;t have privileged access to such platforms.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../all_workflows_parameters/">« Index of Workflows Parameters</a><a class="docs-footer-nextpage" href="../targene/overview/">Overview »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Wednesday 13 November 2024 19:46">Wednesday 13 November 2024</span>. Using Julia version 1.11.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
