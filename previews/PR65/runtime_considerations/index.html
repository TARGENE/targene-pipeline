<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Some Runtime considerations · TarGene</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://TARGENE.github.io/targene-pipeline/runtime_considerations/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">TarGene</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../data_sources/">Setting a data source</a></li><li><a class="tocitem" href="../confounding_adjustment/">Adjusting for confounders</a></li><li><a class="tocitem" href="../parameter_specification/">Describing the causal parameters of interest</a></li><li><a class="tocitem" href="../tmle/">Specifying a Targeted Estimator</a></li><li><a class="tocitem" href="../sieve_variance/">Correcting for population relatedness</a></li><li><a class="tocitem" href="../miscellaneous/">Tweaking additional behaviour</a></li></ul></li><li><span class="tocitem">Miscellaneous</span><ul><li><a class="tocitem" href="../nextflow_params/">Index of the pipeline parameters</a></li><li class="is-active"><a class="tocitem" href>Some Runtime considerations</a><ul class="internal"><li><a class="tocitem" href="#Unit-of-work"><span>Unit of work</span></a></li><li><a class="tocitem" href="#Super-Learning:-Cross-validation-scheme"><span>Super Learning: Cross validation scheme</span></a></li><li><a class="tocitem" href="#Algorithms"><span>Algorithms</span></a></li><li><a class="tocitem" href="#Typical-workloads"><span>Typical workloads</span></a></li></ul></li></ul></li><li><span class="tocitem">Developper Guide</span><ul><li><a class="tocitem" href="../project_organization/">Project Organization</a></li><li><a class="tocitem" href="../contribution_guide/">Contributing</a></li></ul></li><li><a class="tocitem" href="../associated_softwares/">Associated Softwares</a></li><li><a class="tocitem" href="../publications/">Related Publications</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Miscellaneous</a></li><li class="is-active"><a href>Some Runtime considerations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Some Runtime considerations</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/TARGENE/targene-pipeline/blob/main/docs/src/runtime_considerations.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Some-Runtime-considerations"><a class="docs-heading-anchor" href="#Some-Runtime-considerations">Some Runtime considerations</a><a id="Some-Runtime-considerations-1"></a><a class="docs-heading-anchor-permalink" href="#Some-Runtime-considerations" title="Permalink"></a></h1><p>If you are running a large scale analysis using TarGene, it is likely that you will need to make some trade offs about the estimation of nuisance parameters to keep the runtime under control. This runtime is mostly driven by the <a href="@ref">Targeted Maximum Likelihood Estimation</a> process which will scale with the size of the study.</p><h2 id="Unit-of-work"><a class="docs-heading-anchor" href="#Unit-of-work">Unit of work</a><a id="Unit-of-work-1"></a><a class="docs-heading-anchor-permalink" href="#Unit-of-work" title="Permalink"></a></h2><p>The unit of work is represented by a set of treatment variables, typically one or multiple SNPs and a set of outcome variables (phenotypes). This unit of work, which corresponds to a Phenome-Wide association study, can be coarsely decomposed as follows:</p><ol><li>One estimation of the propensity score: <span>$P(T|W)$</span> as specified in the <code>ESTIMATORFILE</code> configuration file.</li><li>For each outcome:<ol><li>The initial estimation of <span>$E[Y|T, W]$</span> as specified in the <code>ESTIMATORFILE</code> configuration file.</li><li>For each treatment case/control setting:<ol><li>The <strong>TMLE step</strong> which roughly consists in fitting a Generalized Linear Model.</li></ol></li></ol></li></ol><p>Let&#39;s illustrate with two examples:</p><ul><li><strong>Scenario 1</strong>:<ul><li>Parameters of interest:<ul><li>Average Treatment Effects of Rs1799971: 0 → 1.</li><li>Average Treatment Effects of Rs1799971: 0 → 2.</li></ul></li><li>Outcomes: Height, diabetes.</li></ul></li></ul><p>This scenario will require the execution of 1 unit of work which will be composed of:</p><p class="math-container">\[1 ⋅ P(T|W) + 2 ⋅ E[Y|T, W] + 4 ⋅ TMLE \ steps\]</p><ul><li><strong>Scenario 2</strong>:<ul><li>Parameters of interest:<ul><li>Average Treatment Effects of Rs4680: 0 → 1.</li><li>Average Treatment Effects of Rs1799971: 0 → 2.</li></ul></li><li>Outcomes: Height</li></ul></li></ul><p>This scenario will require the execution of 2 units of work each composed of:</p><p class="math-container">\[1 ⋅ P(T|W) + 1 ⋅ E[Y|T, W] + 1 ⋅ TMLE \ step\]</p><p>Those units of work can and will be run in parallel by TarGene if resources are available.</p><p>Since it is advocated to use Super Learning for both <span>$P(T|W)$</span> and <span>$E[Y|T, W]$</span>, those operations are typically driving the run time. We also note that estimating <span>$P(T|W)$</span> is usually more expensive than <span>$E[Y|T, W]$</span>.</p><p>Since genetic studies usually involve many SNPs and/or outcomes, we recognize that Super Learning in its purest form, may not always be a practical choice. We describe below some pointer to reduce computational time.</p><h2 id="Super-Learning:-Cross-validation-scheme"><a class="docs-heading-anchor" href="#Super-Learning:-Cross-validation-scheme">Super Learning: Cross validation scheme</a><a id="Super-Learning:-Cross-validation-scheme-1"></a><a class="docs-heading-anchor-permalink" href="#Super-Learning:-Cross-validation-scheme" title="Permalink"></a></h2><p>Because Super Learning employs cross-validation, each learning algorithm in the library needs to be trained <code>n</code> times, <code>n</code> being the number of folds. If the <code>adaptive</code> cross-validation scheme is selected this can result in up to 20 folds cross-validation which will dramatically increase runtime. Here are three alternatives:</p><ol><li>To keep that complexity bounded, one can resort to a fixed k-folds cross-validation where k is an arbitrary number, e.g. 3.</li><li>The least expensive resampling strategy is the <code>resampling: Holdout</code> which will only consist in a single out-of-sample evaluation.</li><li>Don&#39;t use Super Learning. It is perfectly possible to use TarGene without Super Learning.</li></ol><h2 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h2><p>In TarGene, we try to provide a variety of different learning algorithms that can be combined with Super Learning. By restricting the number of algorithms in a Super Learner, runtime will evidently be reduced. Also, the runtime of all learning algorithms is not equal and will depend on hyperparameter choices. Developing an understanding of a learning algorithm helps to make more informed decision about it&#39;s usage.</p><p>Here are a few examples:</p><ul><li><p>The <code>GLMNetRegressor/GLMNetClassifier</code> contain an internal k-fold cross-validation procedure that tunes the regularization hyperparameter. Combined with a p-folds Super Learner, this effectively results in k*p training procedures.</p></li><li><p>The <code>GridSearch...</code> models correspond to self-tuning models that will also perform an inner cross-validation to select the best hyper parameter setting among the provided grid.</p></li><li><p>The <code>XGBoostRegressor/XGBoostClassifier</code> have a <code>tree_method</code> hyperparameter that defaults to <code>exact</code>. The <code>hist</code> method is usually way faster and more appropriate for big datasets.</p></li></ul><h2 id="Typical-workloads"><a class="docs-heading-anchor" href="#Typical-workloads">Typical workloads</a><a id="Typical-workloads-1"></a><a class="docs-heading-anchor-permalink" href="#Typical-workloads" title="Permalink"></a></h2><p>The two following tables present the current runtimes for the two most common genetic association studies: PheWAS and GWAS. In both settings, we use 8 confounding variables and report runtimes for the 4 following learning strategies using an 8-cores compute node:</p><ul><li>GLM: Standard generalized linear model</li><li>GLMNet: GLM with regularization hyperparameter tuning over 3-folds cross-validation.</li><li>XGBoost: This is the famous <a href="https://xgboost.readthedocs.io/en/stable/">gradient boosting trees</a> method with hyperparameter tuning over 10 different settings in a 3-folds cross-validation scheme.</li><li>SL: Super Learning including both the previous XGBoost and GLMNet with a 3-folds cross-validation.</li></ul><h3 id="PheWAS"><a class="docs-heading-anchor" href="#PheWAS">PheWAS</a><a id="PheWAS-1"></a><a class="docs-heading-anchor-permalink" href="#PheWAS" title="Permalink"></a></h3><p>The following figures correspond to a typical PheWAS setting including 768 traits.</p><table><tr><th style="text-align: right">Learning Algorithm</th><th style="text-align: center">Time (hours)</th></tr><tr><td style="text-align: right">GLM</td><td style="text-align: center">2.2</td></tr><tr><td style="text-align: right">GLMNet</td><td style="text-align: center">4.5</td></tr><tr><td style="text-align: right">XGBoost</td><td style="text-align: center">8.8</td></tr><tr><td style="text-align: right">SL</td><td style="text-align: center">30</td></tr></table><h3 id="GWAS"><a class="docs-heading-anchor" href="#GWAS">GWAS</a><a id="GWAS-1"></a><a class="docs-heading-anchor-permalink" href="#GWAS" title="Permalink"></a></h3><p>The following figures correspond to a typical GWAS setting. Since the propensity score&#39;s fit runtime is quite variable across SNPs, we perform TMLE for 100 SNPs and report the mean with two standard deviations. We also report an estimated runtime when scaling to 600 000 SNPs while parallelizing over a high-performance computing platform (200 folds parallelization). While it would be impossible to run a GWAS on a personal laptop, we find that access to a modern computing platform makes this kind of study feasible using Targeted Learning.</p><table><tr><th style="text-align: right">Learning Algorithm</th><th style="text-align: center">Unit Time</th><th style="text-align: center">Projected GWAS Time on HPC</th></tr><tr><td style="text-align: right">GLM</td><td style="text-align: center">13 ± 4 seconds</td><td style="text-align: center">10 hours</td></tr><tr><td style="text-align: right">GLMNet</td><td style="text-align: center">57 ± 48 seconds</td><td style="text-align: center">48 hours</td></tr><tr><td style="text-align: right">XGBoost</td><td style="text-align: center">95 ± 6 seconds</td><td style="text-align: center">72 hours</td></tr><tr><td style="text-align: right">SL</td><td style="text-align: center">451 ± 141 seconds</td><td style="text-align: center">375 hours</td></tr></table></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../nextflow_params/">« Index of the pipeline parameters</a><a class="docs-footer-nextpage" href="../project_organization/">Project Organization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Friday 14 April 2023 08:23">Friday 14 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
